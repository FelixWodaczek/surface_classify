{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12385670",
   "metadata": {},
   "source": [
    "# Produce Plots for Publication\n",
    "\n",
    "Use self built surface classification library `surface_classify` available at https://github.com/FelixWodaczek/surface_classify.git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216e826",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../py_src\")\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sort_neigh\n",
    "\n",
    "from ase.io import read as ase_read\n",
    "from ase.neighborlist import natural_cutoffs, NeighborList\n",
    "from dscribe.descriptors import LMBTR, SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc30ab3",
   "metadata": {},
   "source": [
    "## Standard Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../test_data/230111_finalres_newlocalstruct/rh\" # \"../test_data/220705_cunano_mcswap\" \n",
    "n_particles = 1577\n",
    "n_rhod = 15\n",
    "\n",
    "if False:\n",
    "    rcut=4.2 # 4.2 # 2.7 \n",
    "    nmax=4\n",
    "    lmax=3\n",
    "    sigma=0.6\n",
    "    gamma_kernel=1.\n",
    "else:\n",
    "    rcut=5.2 # 4.2 # 2.7 \n",
    "    nmax=12\n",
    "    lmax=12\n",
    "    sigma=1.\n",
    "    gamma_kernel=1.\n",
    "\n",
    "n_spec = 180\n",
    "lmbtr = LMBTR(\n",
    "    species=[\"Rh\", \"Cu\"],\n",
    "#    k2={\n",
    "#        \"geometry\": {\"function\": \"distance\"},\n",
    "#        \"grid\": {\"min\": 0, \"max\": 5, \"n\": 100, \"sigma\": 0.1},\n",
    "#        \"weighting\": {\"function\": \"exp\", \"scale\": 0.5, \"threshold\": 1e-3},\n",
    "#    },\n",
    "    k3={\n",
    "        \"geometry\": {\"function\": \"angle\"},\n",
    "        \"grid\": {\"min\": 0, \"max\": 180, \"n\": n_spec, \"sigma\": 15},\n",
    "        \"weighting\": {\"function\": \"unity\"},\n",
    "    },\n",
    "    periodic=False,\n",
    "    sparse=False,\n",
    "    normalization=\"none\",\n",
    "    flatten=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e182ef9",
   "metadata": {},
   "source": [
    "## Figure 1, Available Sites on Nanoparticle\n",
    "\n",
    "Analyse the available sites in a nanoparticle containing only Rh.\n",
    "\n",
    "### Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56228b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_cu_dir = target_dir + \"/cunanoparticle\"\n",
    "only_cu_path = only_cu_dir + \"/cusingle.lammpstrj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_structures_path = os.path.abspath(\"../src/localstructures_newopt_onlyCu_altered\")\n",
    "\n",
    "cu_classifier = sort_neigh.onlyCuClassifier(\n",
    "    local_structures_path=scaled_structures_path, non_class_max=14\n",
    ")\n",
    "cu_classifier.load_identifiers(\n",
    "    rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "    sigma=sigma, gamma_kernel=gamma_kernel,\n",
    ")\n",
    "\n",
    "rh_classifier = sort_neigh.NeighbourClassifier(\n",
    "    local_structures_path=os.path.abspath(\"../src/localstructures_final_mc\"),\n",
    "    non_class_max=14\n",
    ")\n",
    "rh_classifier.load_identifiers(# descr_func=lmbtr, \n",
    "    rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "    sigma=sigma, gamma_kernel=gamma_kernel,\n",
    ")\n",
    "\n",
    "single_particle_classifier = rh_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d43ad",
   "metadata": {},
   "source": [
    "### Run Analysis via Classifier\n",
    "Use the surface classifier to determine what sites are identified at which position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    soap_base = single_particle_classifier.identification_dict['7'][\"soap_descr\"]\n",
    "    sims = single_particle_classifier.kernel.create(soap_base)\n",
    "    print(sims)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_particle = ase_read(only_cu_path)\n",
    "if True:\n",
    "    full_particle = ase_read('../test_data/221229_saafinal/rh/mc/400.lammpstrj', index=1000)\n",
    "at_pos = full_particle.get_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a15171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "mode=\"class_all\"\n",
    "\n",
    "cut_off = natural_cutoffs(full_particle, mult=.98)# mult=0.98)\n",
    "neighbour_list = NeighborList(cut_off, bothways=True, self_interaction=False)\n",
    "neighbour_list.update(full_particle)\n",
    "\n",
    "cu_cat_counter = np.zeros(shape=(single_particle_classifier.n_classes), dtype=np.int32)\n",
    "categories = np.zeros((len(full_particle),), dtype=np.int32)\n",
    "neighbours = np.zeros((len(full_particle),), dtype=np.int32)\n",
    "\n",
    "ind_soaps = np.zeros((len(full_particle), single_particle_classifier.descr.get_number_of_features()))\n",
    "for index in range(len(full_particle)):\n",
    "    neighbour_indices, trash = neighbour_list.get_neighbors(index)\n",
    "    neighbour_indices = np.append(np.array([index]), neighbour_indices, axis=0)\n",
    "    neighbour_particle = full_particle[neighbour_indices]\n",
    "    \n",
    "    # Make center atom Rh\n",
    "    neighbour_particle.symbols[:] = 'Cu'\n",
    "    neighbour_particle.symbols[0] = 'Rh'\n",
    "    \n",
    "    ind_soaps[index] = single_particle_classifier.descr.create(neighbour_particle, positions=[0])\n",
    "    n_neigh, class_id = single_particle_classifier.classify(neighbour_particle, mode=mode, ensure_position=False)\n",
    "\n",
    "    cu_cat_counter[class_id] += 1\n",
    "    neighbours[index] = int(n_neigh)\n",
    "    categories[index] = int(class_id)\n",
    "    if int(class_id) == 8:\n",
    "        print(neighbour_particle)\n",
    "        print(neighbour_particle.get_chemical_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(cu_cat_counter)):\n",
    "    print(single_particle_classifier.id_to_cat(ii), ': %u'%cu_cat_counter[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d640c",
   "metadata": {},
   "source": [
    "### Unsupervised Machine Learning\n",
    "Use unsupervised ML to perform the same task and compare results afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, Birch\n",
    "from dscribe.descriptors import SOAP\n",
    "\n",
    "ml_classifier = sort_neigh.USMLClassifier()\n",
    "\n",
    "train_on_particle = False\n",
    "if train_on_particle:\n",
    "    n_clust = ml_classifier.train_on_particle(\n",
    "        full_particle,\n",
    "        soap_species=[\"Cu\"], dim_red=PCA(n_components=4), \n",
    "        clusterer=Birch(n_clusters=10),\n",
    "        rcut=rcut, nmax=nmax, lmax=lmax, sigma=sigma\n",
    "    )\n",
    "else:\n",
    "    n_clust = ml_classifier._train_on_data(\n",
    "        ind_soaps,\n",
    "        dim_red=PCA(n_components=20), clusterer=Birch(n_clusters=8)\n",
    "    )\n",
    "    ml_classifier.descr = single_particle_classifier.descr\n",
    "\n",
    "# soaps = ml_classifier.descr.create(full_particle)\n",
    "reduced = ml_classifier.dim_red.transform(ind_soaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fedf2",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Create view of nanoparticle and reduced mapping for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming Dict for better labels:\n",
    "pretty_label = True\n",
    "if pretty_label:\n",
    "    prettylabel_dict = {\n",
    "            \"12\": \"12 neighbours\",\n",
    "            \"11\": \"11 neighbours\",\n",
    "            \"3_111_ad_atom\": \"111 adatom\",\n",
    "            \"4_111_ad_atom_pair\": \"111 adatom_pair\",\n",
    "            \"4_100_ad_atom\": \"100 adatom\",\n",
    "            \"5_211_ad_atom\": \"211 adatom\" ,\n",
    "            \"5_110_ad_atom\": \"110 adatom\",\n",
    "            \"5_111_terrace\": \"111 terrace\",\n",
    "            \"6_100-110_interface\": \"100-110 interface\",\n",
    "            \"6_100_terrace\": \"100 terrace\",\n",
    "            \"7_110\": \"110\",\n",
    "            \"7_211\": \"211\",\n",
    "            \"8_100\": \"100\",\n",
    "            \"8_111_vacant_site\": \"111 vacancy\",\n",
    "            \"9_111\": \"111\",\n",
    "            \"9_invalid\": \"9 invalid\",\n",
    "            \"9_invalid_2\": \"9 invalid2\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_categories(a_categories, labels=None):\n",
    "    c_range = np.arange(np.max(a_categories), np.min(a_categories)-2, -1)\n",
    "    if labels is not None and len(c_range)-1 != len(labels):\n",
    "        raise ValueError(\"Range of argument 'counter' needs to be same length as argument 'labels' if given.\")\n",
    "        \n",
    "    ret_cats = a_categories.copy()\n",
    "    \n",
    "    if labels is not None:\n",
    "        ret_labels = labels.copy()\n",
    "    \n",
    "    reduce_at_this = False\n",
    "    for value_index, value in enumerate(c_range):\n",
    "        reduce_at_next = value not in ret_cats\n",
    "        \n",
    "        if reduce_at_this:\n",
    "            largereq_than_last = ret_cats > value\n",
    "            ret_cats[largereq_than_last] -= 1\n",
    "            if labels is not None:\n",
    "                ret_labels.pop(len(c_range)-value_index-1)\n",
    "\n",
    "        reduce_at_this = reduce_at_next\n",
    "        \n",
    "    ret_cats -= np.min(ret_cats)\n",
    "    return ret_cats, ret_labels\n",
    "\n",
    "        \n",
    "def cmap_from_categories(colors, or_map_name=\"tab20\", n_orcolors=20):\n",
    "    c_range = np.max(colors)-np.min(colors)+1\n",
    "    normed_colors = (colors-np.min(colors))/(c_range-1)\n",
    "    normed_colors *= (c_range-1)/(c_range)\n",
    "    normed_colors += 1./(2*c_range)\n",
    "\n",
    "    c_ticks = np.linspace(0, 1, c_range*2+1, endpoint=True)[1::2]\n",
    "\n",
    "    tab20 = cm.get_cmap(or_map_name, 256)\n",
    "    color_range = np.linspace(0, c_range/float(n_orcolors), 500, endpoint=False)\n",
    "    cmap = ListedColormap(tab20(color_range))\n",
    "    \n",
    "    return normed_colors, cmap, c_ticks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib auto\n",
    "plt.ion()\n",
    "\n",
    "cond = np.s_[...] # neighbours < 17\n",
    "\n",
    "colors = categories[cond].copy()\n",
    "# colors = n_clust\n",
    "\n",
    "c_labels = np.arange(np.min(colors), np.max(colors)+1)\n",
    "c_labels = [single_particle_classifier.id_to_cat(c_label) for c_label in c_labels]\n",
    "\n",
    "order_by_neighbors = True\n",
    "if order_by_neighbors:\n",
    "    colors[colors==np.min(colors)] = np.max(colors) + 1\n",
    "    colors[colors==np.min(colors)] = np.max(colors) + 1\n",
    "    c_labels.append(c_labels[0])\n",
    "    c_labels.append(c_labels[1])\n",
    "    c_labels.pop(0)\n",
    "    c_labels.pop(0)\n",
    "    \n",
    "    while(len(c_labels) != np.max(colors) + 1 - np.min(colors)):\n",
    "          c_labels.pop(0)\n",
    "    \n",
    "cont_values, c_labels = norm_categories(colors, labels=c_labels)\n",
    "cat_clabels = c_labels.copy()\n",
    "\n",
    "cat_normed_colors, cat_cmap, cat_cticks = cmap_from_categories(cont_values, or_map_name='tab10', n_orcolors=10)\n",
    "\n",
    "label_color_dict = {c_label: color for c_label, color in zip(c_labels, cat_cticks)}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "sc = ax.scatter(\n",
    "    at_pos[cond, 0], at_pos[cond, 1], at_pos[cond, 2], c=cat_normed_colors, cmap=cat_cmap, alpha=1,\n",
    "    s=800, edgecolors=\"k\", vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "if pretty_label:\n",
    "    plot_labels = [\n",
    "        prettylabel_dict[c_label] if c_label in prettylabel_dict.keys() else c_label for c_label in c_labels\n",
    "    ]\n",
    "else:\n",
    "    plot_labels = c_labels\n",
    "    \n",
    "ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "bar = fig.colorbar(sc)\n",
    "bar.set_ticks(cat_cticks)\n",
    "bar.set_ticklabels(plot_labels)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"threed_particle.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75219daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soaps_from_classifier = []\n",
    "labels = []\n",
    "\n",
    "for key in single_particle_classifier.identification_dict.keys():\n",
    "    entry = single_particle_classifier.identification_dict[key]\n",
    "    if entry is not None:\n",
    "        soaps_from_classifier.append(entry[\"soap_descr\"][:, 0, :])\n",
    "        labels.append(entry[\"id\"])\n",
    "\n",
    "buff = soaps_from_classifier[0].copy()\n",
    "for ii_soap in range(1, len(soaps_from_classifier)):\n",
    "    buff = np.append(buff, soaps_from_classifier[ii_soap], axis=0)\n",
    "\n",
    "soaps_from_classifier = buff.copy()\n",
    "del buff\n",
    "\n",
    "buff = []\n",
    "for label in labels:\n",
    "    for entry in label:\n",
    "        buff.append(entry)\n",
    "\n",
    "labels=buff\n",
    "del buff\n",
    "\n",
    "if pretty_label:\n",
    "    labels = [\n",
    "        prettylabel_dict[blabel] if blabel in prettylabel_dict.keys() else blabel for blabel in labels\n",
    "    ]\n",
    "print(labels)\n",
    "print(soaps_from_classifier.shape)\n",
    "soap_prediction = ml_classifier.dim_red.transform(soaps_from_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_soaps = True\n",
    "\n",
    "%matplotlib auto\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"PCA Map of Unsupervised Regression\")\n",
    "c_labels = np.arange(np.min(n_clust), np.max(n_clust)+1)\n",
    "normed_colors, cmap, c_ticks = cmap_from_categories(n_clust)\n",
    "\n",
    "sc = ax.scatter(reduced[:, 0], reduced[:, 1], c=normed_colors, cmap=cmap, vmin=0, vmax=1)\n",
    "\n",
    "if compare_soaps:\n",
    "    ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\")\n",
    "\n",
    "    for ii_label, label in enumerate(labels):  \n",
    "        ax.annotate(label, soap_prediction[ii_label, 0:2])\n",
    "    \n",
    "cbar = fig.colorbar(sc)\n",
    "cbar.set_ticks(c_ticks)\n",
    "cbar.set_ticklabels(c_labels)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"unsupervised_ml_pca.pdf\", format='pdf')\n",
    "plt.show()\n",
    "\n",
    "fontsize = 15\n",
    "ms = 120\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.set_title(\"PCA Map of Classification by Similarity\", fontsize=fontsize)\n",
    "sc = ax.scatter(\n",
    "    reduced[:, 0], reduced[:, 1], \n",
    "    c=cat_normed_colors, s=ms, cmap=cat_cmap, vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "if compare_soaps:\n",
    "    ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\", s=ms)\n",
    "    for ii_label, label in enumerate(labels):\n",
    "        ax.text(\n",
    "            soap_prediction[ii_label, 0]+0.5, soap_prediction[ii_label, 1]-0.015, \n",
    "            label, ha='left', fontsize=fontsize-2\n",
    "        )\n",
    "    \n",
    "cbar = fig.colorbar(sc) \n",
    "\n",
    "cbar.set_ticks(cat_cticks)\n",
    "cbar.set_ticklabels(plot_labels, fontsize=fontsize-2)\n",
    "\n",
    "# ax.set_xlim([-7, 21])\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.tick_params(axis='y', labelsize=fontsize-2)\n",
    "ax.set_xlabel('Principal Axis 1', fontsize=fontsize)\n",
    "ax.set_ylabel('Principal Axis 2', fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"classification_pca.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18d50",
   "metadata": {},
   "source": [
    "## Figure 2, Rh Positions over Time\n",
    "After defining all the available positions in the nanoparticle, analyse where the Rh sit in each timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c380940",
   "metadata": {},
   "source": [
    "### Run Evaluation on Files\n",
    "Set `newcats` to `True` to rerun evaluation, otherwise pre-existing evaluation is loaded from .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab57a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folders = [\n",
    "    target_dir+\"/mc\",\n",
    "    target_dir+\"/mcmd\"\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "bulkify = True # Sum up 11 and 12 neighbours to \"bulk\"\n",
    "newcats = False\n",
    "\n",
    "for target_folder in target_folders:\n",
    "    for target_file in glob(target_folder+\"/*.lammpstrj\"):\n",
    "        target_file = os.path.abspath(target_file)\n",
    "        only_file = os.path.basename(target_file).split(\".\")[0]\n",
    "        out_dir = os.path.join(os.path.dirname(target_file), only_file+\"_soap_sorted_counts.txt\")\n",
    "        save_txt_path = os.path.join(os.path.dirname(target_file), only_file+\"_soap_sorted_counts.txt\")\n",
    "        \n",
    "        dir_name = save_txt_path.split(\"/\")[-2]\n",
    "        cur_key = '_'.join([dir_name, only_file])\n",
    "        results_dict[cur_key] = {}\n",
    "        \n",
    "        rh_sorter = sort_neigh.NeighbourSort(\n",
    "            rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "            sigma=sigma, gamma_kernel=gamma_kernel\n",
    "        )\n",
    "        \n",
    "        if newcats:\n",
    "            rh_sorter.init_folder_structure(\n",
    "                target_file,\n",
    "                n_atoms_in_part=n_particles,\n",
    "                out_dir=out_dir\n",
    "            )\n",
    "            rh_cats = rh_sorter.create_local_structure(last_n=n_rhod, create_subfolders=False)\n",
    "            rh_sorter.sort_save_cat(save_txt_path, rh_cats)\n",
    "                \n",
    "        sorted_counts, timesteps, sorted_cats = rh_sorter.load_sort_cat(save_txt_path)\n",
    "    \n",
    "        if bulkify:\n",
    "            bulk_args = []\n",
    "            for ii_scat, scat in enumerate(sorted_cats):\n",
    "                try:\n",
    "                    if int(scat) >= 10 and int(scat) < 99:\n",
    "                        bulk_args.append(ii_scat)\n",
    "                except:\n",
    "                    pass\n",
    "            bulk_args = np.array(bulk_args)\n",
    "            bulk_slicer = np.s_[:, bulk_args]\n",
    "            sorted_counts = np.append(\n",
    "                sorted_counts, np.sum(\n",
    "                    sorted_counts[bulk_slicer], axis=-1\n",
    "                )[:, np.newaxis], axis=-1\n",
    "            )\n",
    "            sorted_cats.append('bulk')\n",
    "            sorted_counts[bulk_slicer] = 0\n",
    "        \n",
    "        results_dict[cur_key][\"sorted_counts\"] = sorted_counts\n",
    "        results_dict[cur_key][\"timesteps\"] = timesteps\n",
    "        results_dict[cur_key][\"sorted_cats\"] = sorted_cats\n",
    "            \n",
    "        if False: # only_file == '500':\n",
    "            with open(save_txt_path, 'r') as f:\n",
    "                header = f.read().split('\\n')[:2]\n",
    "                for ii_line, line in enumerate(header):\n",
    "                    header[ii_line] = line[2:]\n",
    "                    \n",
    "                header = '\\n'.join(header)\n",
    "                \n",
    "                print_cat = np.zeros((len(timesteps), sorted_counts.shape[1]+1), dtype=np.int32)\n",
    "                print_cat[:, 0] = np.arange(len(timesteps))\n",
    "                print_cat[:, 1:] = sorted_counts\n",
    "                f.close()\n",
    "\n",
    "            np.savetxt(save_txt_path, print_cat, header=header, fmt='%u')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db223b22",
   "metadata": {},
   "source": [
    "### Plot Raw Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a225c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "counter = 0\n",
    "for target_folder in target_folders:\n",
    "    for target_file in glob(target_folder+\"/*.lammpstrj\"):\n",
    "        target_file = os.path.abspath(target_file)\n",
    "        only_file = os.path.basename(target_file).split(\".\")[0]\n",
    "        out_dir = os.path.join(os.path.dirname(target_file), only_file+\"_out\")\n",
    "        save_txt_path = os.path.join(os.path.dirname(target_file), only_file+\"_out.txt\")\n",
    "        \n",
    "        \n",
    "        dir_name = save_txt_path.split(\"/\")[-2]\n",
    "        cur_key = '_'.join([dir_name, only_file])\n",
    "        \n",
    "        sorted_counts = results_dict[cur_key][\"sorted_counts\"] \n",
    "        timesteps = results_dict[cur_key][\"timesteps\"]\n",
    "        sorted_cats = results_dict[cur_key][\"sorted_cats\"]\n",
    "        \n",
    "        fig_list, ax_list = rh_sorter.plot_dist(\n",
    "            sorted_cats, sorted_counts, show_plot=False\n",
    "        )\n",
    "        print(cur_key)\n",
    "        fig_list.pop(1)\n",
    "        ax_list.pop(1)\n",
    "        \n",
    "        plt.show()\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4664f53",
   "metadata": {},
   "source": [
    "### Plot Total Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab891ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sites = np.bincount(categories)\n",
    "norm_dict = {}\n",
    "for ii_site, n_site in enumerate(total_sites):\n",
    "    norm_dict[single_particle_classifier.id_to_cat(ii_site)] = n_site\n",
    "    print(\"Total number of %s: %u\"%(single_particle_classifier.id_to_cat(ii_site), n_site))\n",
    "\n",
    "if False:   \n",
    "    for n_class in range(single_particle_classifier.n_classes):\n",
    "        c_name = single_particle_classifier.id_to_cat(n_class)\n",
    "        try:\n",
    "            norm_dict[c_name]\n",
    "        except:\n",
    "            print(c_name)\n",
    "            norm_dict[c_name] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41841718",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"6_211110_corner\": '6_100-110_interface',\n",
    "    \"7_211_surf\": '7_211', \n",
    "    \"8_terminal\": '8_100',\n",
    "    \"9_111_term\": '9_111'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde6887",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fontsize=20\n",
    "\n",
    "sorted_keys = []\n",
    "for key in results_dict.keys():\n",
    "    sorted_keys.append(key)\n",
    "sorted_keys.sort()\n",
    "\n",
    "norm_counter = True\n",
    "plot_sidebyside = False\n",
    "\n",
    "for ii_key, key in enumerate(sorted_keys):\n",
    "    if ii_key%3 == 0:\n",
    "        fig, axis = plt.subplots(figsize=(12,8))\n",
    "        widths = np.array([-0.3, 0, 0.3])\n",
    "        alphas = [0.2, 0.5, 1]\n",
    "        \n",
    "        sorted_cats = results_dict[key][\"sorted_cats\"]\n",
    "        \n",
    "        n_cats = len(sorted_cats)\n",
    "        draw_cats = np.zeros((3, n_cats), dtype=np.float64)\n",
    "        max_steps = 0\n",
    "        \n",
    "        for jj_cat_key, cat_keys in enumerate(sorted_keys[ii_key:ii_key+3]):\n",
    "            cur_counts = results_dict[cat_keys][\"sorted_counts\"]\n",
    "            draw_cats[jj_cat_key, :] = np.sum(cur_counts, axis=0)\n",
    "            assert np.sum(draw_cats[jj_cat_key, :]) == (cur_counts.shape[0] * n_rhod), np.sum(draw_cats[jj_cat_key, :])\n",
    "            draw_cats[jj_cat_key, :] = draw_cats[jj_cat_key, :] / (cur_counts.shape[0] * n_rhod)\n",
    "            draw_cats[jj_cat_key, :] *= 100\n",
    "            \n",
    "        total_cats = np.sum(draw_cats, axis=0)\n",
    "        is_nonzero = total_cats != 0\n",
    "        total_nonzero = np.sum(is_nonzero)\n",
    "        x_locs = np.arange(total_nonzero)\n",
    "        \n",
    "        draw_cats = draw_cats[:, is_nonzero]\n",
    "        \n",
    "        not_zero_cats = []\n",
    "        for ii_count, more_than_zero in enumerate(is_nonzero):\n",
    "            if more_than_zero:\n",
    "                not_zero_cats.append(sorted_cats[ii_count])\n",
    "                \n",
    "        new_colors_counter = 0\n",
    "        not_zero_colors = []\n",
    "        is_in_prev = np.ones((len(not_zero_cats),), dtype=bool)\n",
    "        for ii_nzcat, nz_cat in enumerate(not_zero_cats):\n",
    "            try: # category is in previous cmap\n",
    "                not_zero_colors.append(cat_clabels.index(nz_cat))\n",
    "            except:\n",
    "                try:\n",
    "                    not_zero_colors.append(cat_clabels.index(rename_dict[nz_cat]))\n",
    "                except:\n",
    "                    print(nz_cat)\n",
    "                    # not_zero_colors.append(len(cat_clabels)+new_colors_counter)\n",
    "                    new_colors_counter += 1\n",
    "                    is_in_prev[ii_nzcat] = False\n",
    "                    \n",
    "        print(new_colors_counter)\n",
    "        not_zero_colors.append(0) # in first category is not in colors\n",
    "            \n",
    "        normed_colors, count_cmap, count_cticks = cmap_from_categories(not_zero_colors, or_map_name='tab10', n_orcolors=10)\n",
    "        normed_colors = normed_colors[:-1]\n",
    "        \n",
    "        legend_patches = []\n",
    "        for kk_draw in range(3):\n",
    "            temperature = sorted_keys[ii_key+kk_draw].split('_')[-1]\n",
    "            width = widths[kk_draw]\n",
    "            draw_cat = draw_cats[kk_draw, :]\n",
    "            \n",
    "            if plot_sidebyside:\n",
    "                side_xclocs = x_locs+(len(draw_cat)*kk_draw)+(1*kk_draw)\n",
    "                axis.bar(\n",
    "                    side_xclocs, draw_cat, width=1,\n",
    "                    color=count_cmap(normed_colors), align='center'\n",
    "                )\n",
    "                annotation_cond = draw_cat != 0\n",
    "                annotations = draw_cat[annotation_cond]\n",
    "                for ll_ann, annotation in enumerate(annotations):\n",
    "                    axis.annotate(\n",
    "                        \"%.4f\"%annotation,\n",
    "                        [side_xclocs[annotation_cond][ll_ann], annotation], \n",
    "                        ha='center', rotation=45, fontsize=fontsize-7\n",
    "                    )\n",
    "            else:\n",
    "                axis.bar(\n",
    "                    x_locs[is_in_prev]+width, draw_cat[is_in_prev], width=0.3,\n",
    "                    color=count_cmap(normed_colors), align='center', alpha=alphas[kk_draw]\n",
    "                )\n",
    "                axis.bar(\n",
    "                    x_locs[np.logical_not(is_in_prev)]+width,\n",
    "                    draw_cat[np.logical_not(is_in_prev)], width=0.3,\n",
    "                    color='k', align='center', alpha=alphas[kk_draw]*0.7\n",
    "                )\n",
    "                annotation_cond = draw_cat != 0\n",
    "                annotations = draw_cat[annotation_cond]\n",
    "                for ll_ann, annotation in enumerate(annotations):\n",
    "                    axis.annotate(\n",
    "                        \"%.4f\"%annotation,\n",
    "                        [x_locs[annotation_cond][ll_ann]+width, annotation*1.1], \n",
    "                        ha='center', rotation=45, fontsize=fontsize-10\n",
    "                    )\n",
    "            \n",
    "            cur_patch = mpatches.Patch(\n",
    "                color='k', label=temperature+\" K\", alpha=alphas[kk_draw]\n",
    "            )\n",
    "            legend_patches.append(cur_patch)\n",
    "            \n",
    "    \n",
    "        axis.set_yscale('log')\n",
    "        if plot_sidebyside:\n",
    "            long_ticklocs = np.zeros((3*len(x_locs),))\n",
    "            long_cats = []\n",
    "            for mm_draw in range(3):\n",
    "                long_ticklocs[mm_draw*len(x_locs):(mm_draw+1)*len(x_locs)] = x_locs+(len(draw_cat)*mm_draw)+(1*mm_draw)\n",
    "                long_cats += not_zero_cats\n",
    "            axis.set_xticks(long_ticklocs, long_cats, fontsize=fontsize-4, rotation=-45)\n",
    "            axis.tick_params(axis='y', labelsize=fontsize-4)\n",
    "        else:\n",
    "            if pretty_label:\n",
    "                plot_labels = [\n",
    "                    prettylabel_dict[nz_cat] if nz_cat in prettylabel_dict.keys() else nz_cat for nz_cat in not_zero_cats\n",
    "                ]\n",
    "            else:\n",
    "                plot_labels = not_zero_cats\n",
    "                \n",
    "            axis.set_xticks(x_locs, plot_labels, fontsize=fontsize-7)\n",
    "            axis.tick_params(axis='y', labelsize=fontsize-7)\n",
    "            \n",
    "        axis.set_xlabel('site type', fontsize=fontsize)\n",
    "        axis.set_ylabel('Rh atoms per surface type [%]', fontsize=fontsize)\n",
    "        axis.set_ylim([axis.get_ylim()[0], 400])\n",
    "        # axis.autoscale(tight=True)\n",
    "        axis.legend(handles=legend_patches, fontsize=fontsize, loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\"barplot_%s.pdf\"%key.split('_')[0], format=\"pdf\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfb893",
   "metadata": {},
   "source": [
    "### Broken Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b76fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 100\n",
    "\n",
    "\n",
    "for ii_key, key in enumerate(sorted_keys):\n",
    "    if ii_key%3 == 0:\n",
    "        fig, axis = plt.subplots(figsize=(12,8))\n",
    "        widths = np.array([-0.3, 0, 0.3])\n",
    "        alphas = [0.2, 0.5, 1]\n",
    "        \n",
    "        sorted_cats = results_dict[key][\"sorted_cats\"]\n",
    "        \n",
    "        n_cats = len(sorted_cats)\n",
    "        draw_cats = np.zeros((3, n_cats), dtype=np.float64)\n",
    "        draw_errs = np.zeros((3, n_cats), dtype=np.float64)\n",
    "        max_steps = 0\n",
    "\n",
    "        for jj_cat_key, cat_keys in enumerate(sorted_keys[ii_key:ii_key+3]):\n",
    "            cur_counts = results_dict[cat_keys][\"sorted_counts\"]\n",
    "            draw_cats[jj_cat_key, :] = np.sum(cur_counts, axis=0)\n",
    "            assert np.sum(draw_cats[jj_cat_key, :]) == (cur_counts.shape[0] * n_rhod), np.sum(draw_cats[jj_cat_key, :])\n",
    "            draw_cats[jj_cat_key, :] = draw_cats[jj_cat_key, :] / (cur_counts.shape[0] * n_rhod)\n",
    "            draw_cats[jj_cat_key, :] *= 100\n",
    "\n",
    "            draw_errs[jj_cat_key, :] = sort_neigh.NeighbourSort.block_average(cur_counts, block_size=block_size)\n",
    "            draw_errs[jj_cat_key, :] = draw_errs[jj_cat_key, :] / (cur_counts.shape[0] * n_rhod)\n",
    "            draw_errs[jj_cat_key, :] *= 100\n",
    "            \n",
    "        total_cats = np.sum(draw_cats, axis=0)\n",
    "        is_nonzero = total_cats != 0\n",
    "        total_nonzero = np.sum(is_nonzero)\n",
    "        x_locs = np.arange(total_nonzero)\n",
    "\n",
    "        axis.plot(draw_cats[:, is_nonzero])\n",
    "        for plarg in np.argwhere(is_nonzero):\n",
    "            baseline = draw_cats[:, plarg].squeeze()\n",
    "            fill = draw_errs[:, plarg].squeeze()\n",
    "            axis.fill_between(np.arange(3), baseline - fill, baseline+fill, alpha=0.6)\n",
    "\n",
    "        # axis.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819f110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "89c38489e3a3631c28bb34ee29ee1d19eecb11ca19c23361330a3cc012ae8209"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
