{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12385670",
   "metadata": {},
   "source": [
    "# Produce Plots for Publication\n",
    "\n",
    "Use self built surface classification library `surface_classify` available at https://github.com/FelixWodaczek/surface_classify.git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216e826",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../py_src\")\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sort_neigh\n",
    "\n",
    "from ase.io import read as ase_read\n",
    "from ase.neighborlist import natural_cutoffs, NeighborList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc30ab3",
   "metadata": {},
   "source": [
    "## Standard Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../test_data/220705_cunano_mcswap\"\n",
    "n_particles = 1577\n",
    "n_rhod = 15\n",
    "\n",
    "rcut=2.7 # 4.2\n",
    "nmax=4\n",
    "lmax=3\n",
    "sigma=0.6\n",
    "gamma_kernel=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e182ef9",
   "metadata": {},
   "source": [
    "## Figure 1, Available Sites on Nanoparticle\n",
    "\n",
    "Analyse the available sites in a nanoparticle containing only Rh.\n",
    "\n",
    "### Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56228b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_cu_dir = target_dir + \"/cunanoparticle\"\n",
    "only_cu_path = only_cu_dir + \"/cusingle.lammpstrj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_structures_path = os.path.abspath(\"../src/localstructures_newopt_onlyCu_altered\")\n",
    "\n",
    "cu_classifier = sort_neigh.onlyCuClassifier(\n",
    "    local_structures_path=scaled_structures_path, non_class_max=12\n",
    ")\n",
    "cu_classifier.load_identifiers(\n",
    "    rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "    sigma=sigma, gamma_kernel=gamma_kernel,\n",
    ")\n",
    "\n",
    "rh_classifier = sort_neigh.NeighbourClassifier(local_structures_path=os.path.abspath(\"../src/localstructures_newopt\"))\n",
    "rh_classifier.load_identifiers(\n",
    "    rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "    sigma=sigma, gamma_kernel=gamma_kernel,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d43ad",
   "metadata": {},
   "source": [
    "### Run Analysis via Classifier\n",
    "Use the surface classifier to determine what sites are identified at which position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a15171",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"class_all\"\n",
    "\n",
    "full_particle = ase_read(only_cu_path)\n",
    "at_pos = full_particle.get_positions()\n",
    "\n",
    "cut_off = natural_cutoffs(full_particle, mult=0.98)# mult=0.98)\n",
    "neighbour_list = NeighborList(cut_off, bothways=True, self_interaction=False)\n",
    "neighbour_list.update(full_particle)\n",
    "\n",
    "cu_cat_counter = np.zeros(shape=(cu_classifier.n_classes), dtype=np.int32)\n",
    "categories = np.zeros((len(full_particle),), dtype=np.int32)\n",
    "neighbours = np.zeros((len(full_particle),), dtype=np.int32)\n",
    "\n",
    "ind_soaps = np.zeros((len(full_particle), cu_classifier.soap.get_number_of_features()))\n",
    "for index in range(len(full_particle)):\n",
    "    neighbour_indices, trash = neighbour_list.get_neighbors(index)\n",
    "    neighbour_indices = np.append(np.array([index]), neighbour_indices, axis=0)\n",
    "    neighbour_particle = full_particle[neighbour_indices]\n",
    "    \n",
    "    ind_soaps[index] = cu_classifier.soap.create(neighbour_particle, positions=[0])\n",
    "    n_neigh, class_id = cu_classifier.classify(neighbour_particle, mode=mode, ensure_position=False)\n",
    "\n",
    "    cu_cat_counter[class_id] += 1\n",
    "    neighbours[index] = int(n_neigh)\n",
    "    categories[index] = int(class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d640c",
   "metadata": {},
   "source": [
    "### Unsupervised Machine Learning\n",
    "Use unsupervised ML to perform the same task and compare results afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, Birch\n",
    "from dscribe.descriptors import SOAP\n",
    "\n",
    "ml_classifier = sort_neigh.USMLClassifier()\n",
    "\n",
    "train_on_particle = True\n",
    "if train_on_particle:\n",
    "    n_clust = ml_classifier.train_on_particle(\n",
    "        full_particle,\n",
    "        soap_species=[\"Cu\"], dim_red=PCA(n_components=4), clusterer=Birch(n_clusters=8),\n",
    "        rcut=rcut, nmax=nmax, lmax=lmax, sigma=sigma,\n",
    "    )\n",
    "else:\n",
    "    n_clust = ml_classifier._train_on_data(\n",
    "        ind_soaps,\n",
    "        dim_red=PCA(n_components=20), clusterer=Birch(n_clusters=8)\n",
    "    )\n",
    "    ml_classifier.soaper = cu_classifier.soap\n",
    "\n",
    "soaps = ml_classifier.soaper.create(full_particle)\n",
    "reduced = ml_classifier.dim_red.transform(soaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fedf2",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Create view of nanoparticle and reduced mapping for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_categories(a_categories, labels=None):\n",
    "    c_range = np.arange(np.max(a_categories), np.min(a_categories)-2, -1)\n",
    "    if labels is not None and len(c_range)-1 != len(labels):\n",
    "        raise ValueError(\"Range of argument 'counter' needs to be same length as argument 'labels' if given.\")\n",
    "        \n",
    "    ret_cats = a_categories.copy()\n",
    "    \n",
    "    if labels is not None:\n",
    "        ret_labels = labels.copy()\n",
    "    \n",
    "    reduce_at_this = False\n",
    "    for value_index, value in enumerate(c_range):\n",
    "        reduce_at_next = value not in ret_cats\n",
    "        \n",
    "        if reduce_at_this:\n",
    "            largereq_than_last = ret_cats > value\n",
    "            ret_cats[largereq_than_last] -= 1\n",
    "            if labels is not None:\n",
    "                ret_labels.pop(len(c_range)-value_index-1)\n",
    "\n",
    "        reduce_at_this = reduce_at_next\n",
    "        \n",
    "    ret_cats -= np.min(ret_cats)\n",
    "    return ret_cats, ret_labels\n",
    "\n",
    "        \n",
    "def cmap_from_categories(colors, or_map_name=\"tab20\", n_orcolors=20):\n",
    "    c_range = np.max(colors)-np.min(colors)+1\n",
    "    normed_colors = (colors-np.min(colors))/(c_range-1)\n",
    "    normed_colors *= (c_range-1)/(c_range)\n",
    "    normed_colors += 1./(2*c_range)\n",
    "\n",
    "    c_ticks = np.linspace(0, 1, c_range*2+1, endpoint=True)[1::2]\n",
    "\n",
    "    tab20 = cm.get_cmap(or_map_name, 256)\n",
    "    color_range = np.linspace(0, c_range/float(n_orcolors), 500, endpoint=False)\n",
    "    cmap = ListedColormap(tab20(color_range))\n",
    "    \n",
    "    return normed_colors, cmap, c_ticks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib auto\n",
    "plt.ion()\n",
    "\n",
    "cond = np.s_[...] # neighbours < 17\n",
    "\n",
    "colors = categories[cond].copy()\n",
    "\n",
    "c_labels = np.arange(np.min(colors), np.max(colors)+1)\n",
    "c_labels = [cu_classifier.id_to_cat(c_label) for c_label in c_labels]\n",
    "\n",
    "order_by_neighbors = True\n",
    "if order_by_neighbors:\n",
    "    colors[colors==np.min(colors)] = np.max(colors) + 1\n",
    "    colors[colors==np.min(colors)] = np.max(colors) + 1\n",
    "    c_labels.append(c_labels[0])\n",
    "    c_labels.append(c_labels[1])\n",
    "    c_labels.pop(0)\n",
    "    c_labels.pop(0)\n",
    "    \n",
    "    while(len(c_labels) != np.max(colors) + 1 - np.min(colors)):\n",
    "          c_labels.pop(0)\n",
    "    \n",
    "cont_values, c_labels = norm_categories(colors, labels=c_labels)\n",
    "cat_clabels = c_labels.copy()\n",
    "\n",
    "cat_normed_colors, cat_cmap, cat_cticks = cmap_from_categories(cont_values, or_map_name='tab10', n_orcolors=10)\n",
    "\n",
    "label_color_dict = {c_label: color for c_label, color in zip(c_labels, cat_cticks)}\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "sc = ax.scatter(\n",
    "    at_pos[cond, 0], at_pos[cond, 1], at_pos[cond, 2], c=cat_normed_colors, cmap=cat_cmap, alpha=1,\n",
    "    s=800, edgecolors=\"k\", vmin=0, vmax=1\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(sc) \n",
    "cbar.set_ticks(cat_cticks)\n",
    "cbar.set_ticklabels(c_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75219daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soaps_from_classifier = []\n",
    "labels = []\n",
    "\n",
    "for key in cu_classifier.identification_dict.keys():\n",
    "    entry = cu_classifier.identification_dict[key]\n",
    "    if entry is not None:\n",
    "        soaps_from_classifier.append(entry[\"soap_descr\"][:, 0, :])\n",
    "        labels.append(entry[\"id\"])\n",
    "\n",
    "buff = soaps_from_classifier[0].copy()\n",
    "for ii_soap in range(1, len(soaps_from_classifier)):\n",
    "    buff = np.append(buff, soaps_from_classifier[ii_soap], axis=0)\n",
    "\n",
    "soaps_from_classifier = buff.copy()\n",
    "del buff\n",
    "\n",
    "buff = []\n",
    "for label in labels:\n",
    "    for entry in label:\n",
    "        buff.append(entry)\n",
    "\n",
    "labels=buff\n",
    "del buff\n",
    "\n",
    "soap_prediction = ml_classifier.dim_red.transform(soaps_from_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_soaps = True\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"PCA Map of Unsupervised Regression\")\n",
    "c_labels = np.arange(np.min(n_clust), np.max(n_clust)+1)\n",
    "normed_colors, cmap, c_ticks = cmap_from_categories(n_clust)\n",
    "\n",
    "sc = ax.scatter(reduced[:, 0], reduced[:, 1], c=normed_colors, cmap=cmap, vmin=0, vmax=1)\n",
    "\n",
    "if compare_soaps:\n",
    "    ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\")\n",
    "\n",
    "    for ii_label, label in enumerate(labels):  \n",
    "        ax.annotate(label, soap_prediction[ii_label, 0:2])\n",
    "    \n",
    "cbar = fig.colorbar(sc)\n",
    "cbar.set_ticks(c_ticks)\n",
    "cbar.set_ticklabels(c_labels)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"PCA Map of Classification by Similarity\")\n",
    "sc = ax.scatter(reduced[:, 0], reduced[:, 1], c=cat_normed_colors, cmap=cat_cmap, vmin=0, vmax=1)\n",
    "\n",
    "if compare_soaps:\n",
    "    ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\")\n",
    "    for ii_label, label in enumerate(labels):  \n",
    "        ax.annotate(label, soap_prediction[ii_label, 0:2])\n",
    "    \n",
    "cbar = fig.colorbar(sc) \n",
    "cbar.set_ticks(cat_cticks)\n",
    "cbar.set_ticklabels(cat_clabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c18d50",
   "metadata": {},
   "source": [
    "## Figure 2, Rh Positions over Time\n",
    "After defining all the available positions in the nanoparticle, analyse where the Rh sit in each timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c380940",
   "metadata": {},
   "source": [
    "### Run Evaluation on Files\n",
    "Set `newcats` to `True` to rerun evaluation, otherwise pre-existing evaluation is loaded from .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab57a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folders = [\n",
    "    target_dir+\"/mc\",\n",
    "    target_dir+\"/mcmd\"\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "newcats = False\n",
    "for target_folder in target_folders:\n",
    "    for target_file in glob(target_folder+\"/*.lammpstrj\"):\n",
    "        target_file = os.path.abspath(target_file)\n",
    "        only_file = os.path.basename(target_file).split(\".\")[0]\n",
    "        out_dir = os.path.join(os.path.dirname(target_file), only_file+\"_out\")\n",
    "        save_txt_path = os.path.join(os.path.dirname(target_file), only_file+\"_out.txt\")\n",
    "        \n",
    "        dir_name = save_txt_path.split(\"/\")[-2]\n",
    "        cur_key = '_'.join([dir_name, only_file])\n",
    "        results_dict[cur_key] = {}\n",
    "        \n",
    "        rh_sorter = sort_neigh.NeighbourSort(\n",
    "            rcut=rcut, nmax=nmax, lmax=lmax, \n",
    "            sigma=sigma, gamma_kernel=gamma_kernel\n",
    "        )\n",
    "        \n",
    "        if newcats:\n",
    "            rh_sorter.init_folder_structure(\n",
    "                target_file,\n",
    "                n_atoms_in_part=n_particles,\n",
    "                out_dir=out_dir\n",
    "            )\n",
    "            rh_cats = rh_sorter.create_local_structure(last_n=n_rhod, create_subfolders=False)\n",
    "            rh_sorter.sort_save_cat(save_txt_path, rh_cats)\n",
    "        \n",
    "        sorted_counts, timesteps, sorted_cats = rh_sorter.load_sort_cat(save_txt_path)\n",
    "        \n",
    "        results_dict[cur_key][\"sorted_counts\"] = sorted_counts\n",
    "        results_dict[cur_key][\"timesteps\"] = timesteps\n",
    "        results_dict[cur_key][\"sorted_cats\"] = sorted_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db223b22",
   "metadata": {},
   "source": [
    "### Plot Raw Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a225c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for target_folder in target_folders:\n",
    "    for target_file in glob(target_folder+\"/*.lammpstrj\"):\n",
    "        target_file = os.path.abspath(target_file)\n",
    "        only_file = os.path.basename(target_file).split(\".\")[0]\n",
    "        out_dir = os.path.join(os.path.dirname(target_file), only_file+\"_out\")\n",
    "        save_txt_path = os.path.join(os.path.dirname(target_file), only_file+\"_out.txt\")\n",
    "        \n",
    "        \n",
    "        dir_name = save_txt_path.split(\"/\")[-2]\n",
    "        cur_key = '_'.join([dir_name, only_file])\n",
    "        \n",
    "        sorted_counts = results_dict[cur_key][\"sorted_counts\"] \n",
    "        timesteps = results_dict[cur_key][\"timesteps\"]\n",
    "        sorted_cats = results_dict[cur_key][\"sorted_cats\"]\n",
    "        \n",
    "        fig_list, ax_list = rh_sorter.plot_dist(\n",
    "            sorted_cats, sorted_counts, show_plot=False\n",
    "        )\n",
    "        \n",
    "        print(cur_key)\n",
    "        fig_list.pop(1)\n",
    "        ax_list.pop(1)\n",
    "        \n",
    "        plt.show()\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4664f53",
   "metadata": {},
   "source": [
    "### Plot Total Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab891ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sites = np.bincount(categories)\n",
    "norm_dict = {}\n",
    "for ii_site, n_site in enumerate(total_sites):\n",
    "    norm_dict[cu_classifier.id_to_cat(ii_site)] = n_site\n",
    "    print(\"Total number of %s: %u\"%(cu_classifier.id_to_cat(ii_site), n_site))\n",
    "    \n",
    "for n_class in range(cu_classifier.n_classes):\n",
    "    c_name = cu_classifier.id_to_cat(n_class)\n",
    "    try:\n",
    "        norm_dict[c_name]\n",
    "    except:\n",
    "        print(c_name)\n",
    "        norm_dict[c_name] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fontsize=20\n",
    "\n",
    "sorted_keys = []\n",
    "for key in results_dict.keys():\n",
    "    sorted_keys.append(key)\n",
    "sorted_keys.sort()\n",
    "\n",
    "norm_counter = True\n",
    "\n",
    "for ii_key, key in enumerate(sorted_keys):\n",
    "    if ii_key%3 == 0:\n",
    "        fig, axis = plt.subplots(figsize=(12,8))\n",
    "        widths = np.array([-0.3, 0, 0.3])\n",
    "        alphas = [0.2, 0.5, 1]\n",
    "        \n",
    "        sorted_cats = results_dict[key][\"sorted_cats\"]\n",
    "        n_cats = len(sorted_cats)\n",
    "        draw_cats = np.zeros((3, n_cats), dtype=np.float64)\n",
    "        max_steps = 0\n",
    "        \n",
    "        for jj_cat_key, cat_keys in enumerate(sorted_keys[ii_key:ii_key+3]):\n",
    "            cur_counts = results_dict[cat_keys][\"sorted_counts\"]\n",
    "            draw_cats[jj_cat_key, :] = np.sum(cur_counts, axis=0)\n",
    "            draw_cats[jj_cat_key, :] = draw_cats[jj_cat_key, :] / (cur_counts.shape[0] * n_rhod)\n",
    "            draw_cats[jj_cat_key, :] *= 100\n",
    "            assert np.sum(draw_cats[jj_cat_key, :]) == 100.\n",
    "\n",
    "        total_cats = np.sum(draw_cats, axis=0)\n",
    "        is_nonzero = total_cats != 0\n",
    "        total_nonzero = np.sum(is_nonzero)\n",
    "        x_locs = np.arange(total_nonzero)\n",
    "        \n",
    "        draw_cats = draw_cats[:, is_nonzero]\n",
    "        \n",
    "        not_zero_cats = []\n",
    "        for ii_count, more_than_zero in enumerate(is_nonzero):\n",
    "            if more_than_zero:\n",
    "                not_zero_cats.append(sorted_cats[ii_count])\n",
    "                \n",
    "        new_colors_counter = 0\n",
    "        not_zero_colors = []\n",
    "        for nz_cat in not_zero_cats:\n",
    "            try: # category is in previous cmap\n",
    "                not_zero_colors.append(cat_clabels.index(nz_cat))\n",
    "            except:\n",
    "                not_zero_colors.append(len(cat_clabels)+new_colors_counter)\n",
    "                new_colors_counter += 1\n",
    "        \n",
    "        not_zero_colors.append(0) # in first category is not in colors\n",
    "            \n",
    "        normed_colors, count_cmap, count_cticks = cmap_from_categories(not_zero_colors, or_map_name='tab10', n_orcolors=10)\n",
    "        normed_colors = normed_colors[:-1]\n",
    "        \n",
    "        \n",
    "        legend_patches = []\n",
    "        for kk_draw in range(3):\n",
    "            temperature = sorted_keys[ii_key+kk_draw].split('_')[-1]\n",
    "            width = widths[kk_draw]\n",
    "            draw_cat = draw_cats[kk_draw, :]\n",
    "            \n",
    "            axis.bar(\n",
    "                x_locs+width, draw_cat, width=0.3,\n",
    "                color=count_cmap(normed_colors), align='center', alpha=alphas[kk_draw]\n",
    "            )\n",
    "            \n",
    "            cur_patch = mpatches.Patch(\n",
    "                color='k', label=temperature+\" K\", alpha=alphas[kk_draw]\n",
    "            )\n",
    "            legend_patches.append(cur_patch)\n",
    "            \n",
    "            annotation_cond = draw_cat != 0\n",
    "            annotations = draw_cat[annotation_cond]\n",
    "            for ll_ann, annotation in enumerate(annotations):\n",
    "                axis.annotate(\n",
    "                    \"%.4f\"%annotation,\n",
    "                    [x_locs[annotation_cond][ll_ann]+width, annotation], \n",
    "                    ha='center', rotation=45, fontsize=fontsize-10\n",
    "                )\n",
    "    \n",
    "        axis.set_yscale('log')\n",
    "        axis.set_xticks(x_locs, not_zero_cats, fontsize=fontsize-4)\n",
    "        axis.tick_params(axis='y', labelsize=fontsize-4)\n",
    "        axis.set_xlabel('surface type', fontsize=fontsize)\n",
    "        axis.set_ylabel('Rh atoms per surface type [%]', fontsize=fontsize)\n",
    "        axis.set_ylim([axis.get_ylim()[0], 400])\n",
    "        # axis.autoscale(tight=True)\n",
    "        axis.legend(handles=legend_patches, fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfb893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
