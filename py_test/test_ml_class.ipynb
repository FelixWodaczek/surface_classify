{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../py_src\")\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sort_neigh\n",
    "\n",
    "from ase.io import read as ase_read\n",
    "from ase.neighborlist import natural_cutoffs, NeighborList\n",
    "from dscribe.descriptors import LMBTR, SOAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../test_data/230104_finalres_justlocalstruct/rh\"\n",
    "only_cu_dir = target_dir + \"/cunanoparticle\"\n",
    "only_cu_path = only_cu_dir + \"/cusingle.lammpstrj\"\n",
    "\n",
    "old_format = False\n",
    "n_particles = 1577\n",
    "n_rhod = 15\n",
    "\n",
    "if False: # finalres\n",
    "    r_cut=4.2 \n",
    "    n_max=4\n",
    "    l_max=3\n",
    "    sigma=0.6\n",
    "    gamma_kernel=1.\n",
    "else: # finalres justlocalstruct\n",
    "    r_cut=5.2\n",
    "    n_max=4\n",
    "    l_max=3\n",
    "    sigma=1.\n",
    "    gamma_kernel=1.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_classifier = sort_neigh.USMLClassifier()\n",
    "\n",
    "use_soap = True\n",
    "load_dim_red = False\n",
    "if use_soap:\n",
    "    descr = SOAP(species=[\"Rh\", \"Cu\"], r_cut=r_cut, n_max=n_max, l_max=l_max, sigma=sigma, periodic=False)\n",
    "else:\n",
    "    n_spec = 180\n",
    "    descr = LMBTR(\n",
    "        species=[\"Rh\", \"Cu\"],\n",
    "    #    k2={\n",
    "    #        \"geometry\": {\"function\": \"distance\"},\n",
    "    #        \"grid\": {\"min\": 0, \"max\": 5, \"n\": 100, \"sigma\": 0.1},\n",
    "    #        \"weighting\": {\"function\": \"exp\", \"scale\": 0.5, \"threshold\": 1e-3},\n",
    "    #    },\n",
    "        k3={\n",
    "            \"geometry\": {\"function\": \"angle\"},\n",
    "            \"grid\": {\"min\": 0, \"max\": 180, \"n\": n_spec, \"sigma\": 2.8},\n",
    "            \"weighting\": {\"function\": \"unity\"},\n",
    "        },\n",
    "        periodic=False,\n",
    "        sparse=False,\n",
    "        normalization=\"none\",\n",
    "        flatten=True\n",
    "    )\n",
    "\n",
    "standard_classifier = sort_neigh.NeighbourClassifier(\n",
    "    local_structures_path=os.path.abspath(\"../src/localstructures_newopt_rh\"),\n",
    "    non_class_max=14\n",
    ")\n",
    "standard_classifier.load_identifiers(descr_func=descr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_particle = ase_read(only_cu_path)\n",
    "if False:\n",
    "    full_particle = ase_read('../test_data/221229_saafinal/rh/mc/600.lammpstrj', index=3000)\n",
    "at_pos = full_particle.get_positions()\n",
    "\n",
    "cut_off = natural_cutoffs(full_particle, mult=0.98)# mult=0.98)\n",
    "neighbour_list = NeighborList(cut_off, bothways=True, self_interaction=False)\n",
    "neighbour_list.update(full_particle)\n",
    "\n",
    "ind_soaps = np.zeros((len(full_particle), descr.get_number_of_features()))\n",
    "surf_soaps = []\n",
    "for index in range(len(full_particle)):\n",
    "    neighbour_indices, trash = neighbour_list.get_neighbors(index)\n",
    "    neighbour_indices = np.append(np.array([index]), neighbour_indices, axis=0)\n",
    "    neighbour_particle = full_particle[neighbour_indices]\n",
    "    \n",
    "    # Make center atom Rh\n",
    "    symbs = neighbour_particle.get_chemical_symbols()\n",
    "    symbs[0] = \"Rh\"\n",
    "    neighbour_particle.set_chemical_symbols(symbs)\n",
    "\n",
    "    ind_soaps[index] = descr.create(neighbour_particle, centers=[0])\n",
    "    if len(neighbour_particle) < 10:\n",
    "        surf_soaps.append(ind_soaps[index])\n",
    "\n",
    "surf_soaps = np.asarray(surf_soaps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Soaps from localstructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soaps_from_classifier = []\n",
    "labels = []\n",
    "\n",
    "for key in standard_classifier.identification_dict.keys():\n",
    "    entry = standard_classifier.identification_dict[key]\n",
    "    if entry is not None:\n",
    "        soaps_from_classifier.append(entry[\"soap_descr\"][:, 0, :])\n",
    "        labels.append(entry[\"id\"])\n",
    "\n",
    "buff = soaps_from_classifier[0].copy()\n",
    "for ii_soap in range(1, len(soaps_from_classifier)):\n",
    "    buff = np.append(buff, soaps_from_classifier[ii_soap], axis=0)\n",
    "\n",
    "soaps_from_classifier = buff.copy()\n",
    "del buff\n",
    "\n",
    "buff = []\n",
    "for label in labels:\n",
    "    for entry in label:\n",
    "        buff.append(entry)\n",
    "\n",
    "labels=buff\n",
    "del buff\n",
    "\n",
    "print(\"Loaded localstructures: \")\n",
    "print(labels)\n",
    "print(soaps_from_classifier.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, Birch\n",
    "from dscribe.descriptors import SOAP\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "train_on_particle = False\n",
    "if train_on_particle:\n",
    "    n_clust = ml_classifier.train_on_particle(\n",
    "        full_particle,\n",
    "        soap_species=[\"Cu\"], dim_red=PCA(n_components=n_components), \n",
    "        clusterer=Birch(n_clusters=10),\n",
    "        r_cut=r_cut, n_max=n_max, l_max=l_max, sigma=sigma\n",
    "    )\n",
    "else:\n",
    "    n_clust = ml_classifier._train_on_data(\n",
    "        soaps_from_classifier, # soaps_from_classifier, # ind_soaps,\n",
    "        dim_red=PCA(n_components=n_components), clusterer=KMeans(n_clusters=10)\n",
    "    )\n",
    "    ml_classifier.descr = descr\n",
    "\n",
    "# soaps = ml_classifier.descr.create(full_particle)\n",
    "reduced_particle = ml_classifier.dim_red.transform(ind_soaps)\n",
    "reduced_surf = ml_classifier.dim_red.transform(surf_soaps)\n",
    "soap_prediction = ml_classifier.dim_red.transform(soaps_from_classifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Atomic Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folders = [\n",
    "    target_dir+\"/mc\",\n",
    "    target_dir+\"/mcmd\"\n",
    "]\n",
    "if old_format:\n",
    "    if use_soap:\n",
    "        load_name = \"_soap.npy\"\n",
    "    else:\n",
    "        load_name = \"_lmbtr.npy\"\n",
    "else:\n",
    "    n_timesteps = 10000\n",
    "    if use_soap:\n",
    "        load_name = \"_soap_%ux%u.txt\"%(n_timesteps, n_rhod)\n",
    "        if load_dim_red:\n",
    "            load_name = \"_soappca_%ux%u.txt\"%(n_timesteps, n_rhod)\n",
    "    else:\n",
    "        load_name = \"_lmbtr_%ux%u.txt\"%(n_timesteps, n_rhod)\n",
    "        if load_dim_red:\n",
    "            load_name = \"_lmbtrpca_%ux%u.txt\"%(n_timesteps, n_rhod)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for target_folder in target_folders:\n",
    "    for target_file in glob(target_folder+\"/*.lammpstrj\"):\n",
    "        target_file = os.path.abspath(target_file)\n",
    "        only_file = os.path.basename(target_file).split(\".\")[0]\n",
    "        save_txt_path = os.path.join(os.path.dirname(target_file), only_file+load_name)\n",
    "\n",
    "        with open(save_txt_path, 'rb') as f:\n",
    "            if old_format:\n",
    "                load_descriptors = np.load(f)\n",
    "            else:\n",
    "                load_descriptors = np.loadtxt(f, dtype=np.float32)\n",
    "                load_descriptors = load_descriptors.reshape((n_timesteps, n_rhod, load_descriptors.shape[-1]))\n",
    "            f.close()\n",
    "\n",
    "        dir_name = save_txt_path.split(\"/\")[-2]\n",
    "        cur_key = '_'.join([dir_name, only_file])\n",
    "        results_dict[cur_key] = {}\n",
    "        if not load_dim_red:\n",
    "            results_dict[cur_key][\"descriptors\"] = load_descriptors.copy()\n",
    "            import_shape = load_descriptors.shape\n",
    "            load_descriptors = load_descriptors.reshape((import_shape[0]*import_shape[1], import_shape[2]))\n",
    "            results_dict[cur_key][\"dim_red\"] = ml_classifier.dim_red.transform(load_descriptors)\n",
    "            results_dict[cur_key][\"dim_red\"] = results_dict[cur_key][\"dim_red\"].reshape((import_shape[0], import_shape[1], results_dict[cur_key][\"dim_red\"].shape[-1]))\n",
    "        else:\n",
    "            results_dict[cur_key][\"dim_red\"] = load_descriptors[..., :n_components]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Reduction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"PCA Map of Unsupervised Regression\")\n",
    "\n",
    "sc = ax.scatter(reduced_particle[:, 0], reduced_particle[:, 1], label='particle')\n",
    "ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\", label=\"localstructures\")\n",
    "for ii_label, label in enumerate(labels):\n",
    "    ax.annotate(label, soap_prediction[ii_label, 0:2])\n",
    "\n",
    "load_descriptors = results_dict[\"mcmd_400\"][\"dim_red\"][..., :2]\n",
    "load_descriptors = load_descriptors.reshape((load_descriptors.shape[0]*load_descriptors.shape[1], load_descriptors.shape[2]))\n",
    "ax.scatter(load_descriptors[:, 0], load_descriptors[:, 1], label='trajectory mcmd')\n",
    "load_descriptors = results_dict[\"mc_400\"][\"dim_red\"][..., :2]\n",
    "load_descriptors = load_descriptors.reshape((load_descriptors.shape[0]*load_descriptors.shape[1], load_descriptors.shape[2]))\n",
    "ax.scatter(load_descriptors[:, 0], load_descriptors[:, 1], label='trajectory mc')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    ml_classifier.clusterer = KMeans(init=soap_prediction, n_clusters=soap_prediction.shape[0])\n",
    "    ml_classifier.clusterer.fit(soap_prediction)\n",
    "\n",
    "clust_min = np.min(soap_prediction, axis=0)\n",
    "clust_max = np.max(soap_prediction, axis=0)\n",
    "clust_diff = clust_max - clust_min\n",
    "clust_min -= clust_diff*0.1\n",
    "clust_max += clust_diff*0.1\n",
    "\n",
    "# Everything too far outside 9 neighbour is considered bulk\n",
    "if soap_prediction[-1, 0] > 0:\n",
    "    bulk_border = clust_max[0]\n",
    "else:\n",
    "    bulk_border = clust_min[0]\n",
    "\n",
    "# Build cluster number for each file in results_dict\n",
    "for key, value in results_dict.items():\n",
    "    load_reduction = value[\"dim_red\"]\n",
    "    import_shape = load_reduction.shape\n",
    "    load_reduction = load_reduction.reshape((import_shape[0]*import_shape[1], import_shape[2]))\n",
    "    clusters = ml_classifier.clusterer.predict(load_reduction)\n",
    "    results_dict[key][\"clusters\"] = clusters.reshape((import_shape[0], import_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def cmap_from_categories(colors, or_map_name=\"tab20\", n_orcolors=20):\n",
    "    c_range = np.max(colors)-np.min(colors)+1\n",
    "    normed_colors = (colors-np.min(colors))/(c_range-1)\n",
    "    normed_colors *= (c_range-1)/(c_range)\n",
    "    normed_colors += 1./(2*c_range)\n",
    "\n",
    "    c_ticks = np.linspace(0, 1, c_range*2+1, endpoint=True)[1::2]\n",
    "\n",
    "    tab20 = cm.get_cmap(or_map_name, 256)\n",
    "    color_range = np.linspace(0, c_range/float(n_orcolors), 500, endpoint=False)\n",
    "    cmap = ListedColormap(tab20(color_range))\n",
    "    \n",
    "    return normed_colors, cmap, c_ticks\n",
    "\n",
    "def norm_to_previous_cats(new_cats, prev_cats):\n",
    "    c_range = np.max(prev_cats)-np.min(prev_cats)+1\n",
    "    normed_colors = (new_cats-np.min(prev_cats))/(c_range-1)\n",
    "    normed_colors *= (c_range-1)/(c_range)\n",
    "    normed_colors += 1./(2*c_range)\n",
    "\n",
    "    return normed_colors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Particle Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prediction = ml_classifier.clusterer.predict(soap_prediction)\n",
    "normed_colors, cmap, c_ticks = cmap_from_categories(target_prediction)\n",
    "centers = ml_classifier.clusterer.cluster_centers_\n",
    "\n",
    "particle_colors = norm_to_previous_cats(ml_classifier.clusterer.predict(reduced_particle), target_prediction)\n",
    "at_pos = full_particle.get_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = np.s_[:]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "sc = ax.scatter(\n",
    "    at_pos[cond, 0], at_pos[cond, 1], at_pos[cond, 2], c=particle_colors, cmap=cmap, alpha=1,\n",
    "    s=800, edgecolors=\"k\", vmin=0, vmax=1\n",
    ")\n",
    "cbar = fig.colorbar(sc)\n",
    "cbar.set_ticks(c_ticks)\n",
    "cbar.set_ticklabels(labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "%matplotlib auto\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"PCA Map of Unsupervised Regression\")\n",
    "\n",
    "sc = ax.scatter(reduced_particle[:, 0], reduced_particle[:, 1], c=particle_colors, label='particle', cmap=cmap, vmin=0, vmax=1)\n",
    "\n",
    "# ax.scatter(soap_prediction[:, 0], soap_prediction[:, 1], c=\"k\", label=\"localstructures\")\n",
    "ax.scatter(centers[:, 0], centers[:, 1], label='centers', c='k', marker='x')\n",
    "for ii_label, label in enumerate(labels):\n",
    "    ax.annotate(label, soap_prediction[ii_label, 0:2])\n",
    "\n",
    "# Make colorbar nice\n",
    "if True:\n",
    "    cbar = fig.colorbar(sc)\n",
    "    cbar.set_ticks(c_ticks)\n",
    "    cbar.set_ticklabels(labels)\n",
    "\n",
    "# Plot clustering borders\n",
    "if False:\n",
    "    x_bords = ax.get_xlim()\n",
    "    x_range = np.linspace(x_bords[0], x_bords[1], 201)\n",
    "    y_bords = ax.get_ylim()\n",
    "    y_range = np.linspace(-50, y_bords[1], 200)\n",
    "\n",
    "    xx_mesh, yy_mesh = np.meshgrid(x_range, y_range)\n",
    "    Z = ml_classifier.clusterer.predict(np.c_[xx_mesh.ravel(), yy_mesh.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx_mesh.shape)\n",
    "    Z = norm_to_previous_cats(Z, target_prediction)\n",
    "    ax.imshow(\n",
    "        Z,\n",
    "        interpolation=\"nearest\",\n",
    "        extent=(xx_mesh.min(), xx_mesh.max(), yy_mesh.min(), yy_mesh.max()),\n",
    "        cmap=cmap,\n",
    "        aspect=\"auto\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "raise ValueError\n",
    "# MC and MCMD plot\n",
    "t = 600\n",
    "load_descriptors = results_dict[\"mc_%u\"%t][\"dim_red\"][..., :2]\n",
    "load_descriptors = load_descriptors.reshape((load_descriptors.shape[0]*load_descriptors.shape[1], load_descriptors.shape[2]))\n",
    "load_colors = results_dict[\"mc_%u\"%t][\"clusters\"]\n",
    "load_colors = load_colors.reshape((load_colors.shape[0]*load_colors.shape[1]))\n",
    "load_colors = norm_to_previous_cats(load_colors, target_prediction)\n",
    "ax.scatter(load_descriptors[:, 0], load_descriptors[:, 1], c=load_colors, label='trajectory mc', cmap=cmap, vmin=0, vmax=1, marker='s')\n",
    "\n",
    "load_descriptors = results_dict[\"mcmd_%u\"%t][\"dim_red\"][..., :2]\n",
    "load_descriptors = load_descriptors.reshape((load_descriptors.shape[0]*load_descriptors.shape[1], load_descriptors.shape[2]))\n",
    "load_colors = results_dict[\"mcmd_%u\"%t][\"clusters\"]\n",
    "load_colors = load_colors.reshape((load_colors.shape[0]*load_colors.shape[1]))\n",
    "load_colors = norm_to_previous_cats(load_colors, target_prediction)\n",
    "ax.scatter(load_descriptors[:, 0], load_descriptors[:, 1], label='trajectory mcmd', c=load_colors, cmap=cmap, vmin=0, vmax=1, marker='>')\n",
    "\n",
    "# Border filter patch\n",
    "border_rect = Rectangle(\n",
    "    xy=clust_min, width=(clust_max-clust_min)[0], height=(clust_max-clust_min)[1], \n",
    "    fill=False, edgecolor='k', linewidth=3,\n",
    "    label='Classification Range'\n",
    ")\n",
    "ax.add_patch(border_rect)\n",
    "ax.vlines(bulk_border, ax.get_ylim()[0], ax.get_ylim()[1], color='r', linewidth=3, label='Bulk Cutoff')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Bar Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['400', '500', '600']\n",
    "index_dict = {'400':0, '500':1, '600':2} # To sort temperature into right spot in bincount array\n",
    "\n",
    "n_clust = ml_classifier.clusterer.n_clusters\n",
    "particle_cats = ml_classifier.clusterer.predict(reduced_particle.astype(np.double))\n",
    "\n",
    "particle_bins = np.bincount(particle_cats, minlength=n_clust)\n",
    "\n",
    "measurement_count = np.zeros((2, 3, n_clust+2), np.int16)\n",
    "n_ts = np.zeros((2, 3), np.int16)\n",
    "for key, value in results_dict.items():\n",
    "    temperature = key.split('_')[-1]\n",
    "    t_ind = index_dict[temperature]\n",
    "    type_ind = int('mcmd' in key) # 0 for mc, 1 for mcmd\n",
    "    \n",
    "    load_reduction = value[\"dim_red\"]\n",
    "    load_reduction = load_reduction.reshape((load_reduction.shape[0]*load_reduction.shape[1], load_reduction.shape[2]))\n",
    "    is_bulk = load_reduction[:, 0] > bulk_border\n",
    "    n_bulk = np.count_nonzero(is_bulk)\n",
    "    in_range = np.logical_and.reduce(np.logical_and(load_reduction > clust_min, load_reduction < clust_max), axis=-1)\n",
    "    n_outrange = np.count_nonzero(np.logical_not(in_range))\n",
    "\n",
    "    load_cats = value[\"clusters\"]\n",
    "    n_ts[type_ind, t_ind] = load_cats.shape[0]\n",
    "    load_cats = load_cats.reshape((load_cats.shape[0]*load_cats.shape[1]))\n",
    "    measurement_count[type_ind, t_ind, :-2] = np.bincount(load_cats[in_range], minlength=n_clust)\n",
    "    measurement_count[type_ind, t_ind, -2] = n_bulk\n",
    "    measurement_count[type_ind, t_ind, -1] = n_outrange - n_bulk\n",
    "\n",
    "used_cats = 0 != np.sum(measurement_count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "draw_ind = 0\n",
    "offsets = np.array([-0.3, 0, 0.3])\n",
    "alphas = [0.2, 0.5, 1]\n",
    "width = 0.3\n",
    "fontsize = 17\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('mc')\n",
    "print(labels)\n",
    "cur_labels = []\n",
    "for ii_label, label in enumerate(labels+['bulk', 'non-classifiable']):\n",
    "    print(label, used_cats[draw_ind, ii_label])\n",
    "    if used_cats[draw_ind, ii_label]:\n",
    "        cur_labels.append(label)\n",
    "\n",
    "draw_percentages = measurement_count[draw_ind, :, :] / (n_ts[draw_ind, :, np.newaxis] * n_rhod)\n",
    "draw_percentages *= 100\n",
    "draw_percentages = measurement_count[draw_ind, :, :]\n",
    "n_cats = np.sum(np.asarray(used_cats[draw_ind, :], np.int8))\n",
    "cat_locs = np.arange(n_cats)\n",
    "\n",
    "for ii_bar in range(3):\n",
    "    ax.bar(cat_locs + offsets[ii_bar], draw_percentages[ii_bar, used_cats[draw_ind, :]], width=width, label=label_list[ii_bar])\n",
    "\n",
    "    for ll_ann, annotation in enumerate(draw_percentages[ii_bar, used_cats[draw_ind, :]]):\n",
    "        ax.annotate(\n",
    "            \"%.4f\"%annotation,\n",
    "            [cat_locs[ll_ann]+offsets[ii_bar], annotation*1.1], \n",
    "            ha='center', rotation=45, fontsize=fontsize-10\n",
    "        )\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks(cat_locs)\n",
    "ax.set_xticklabels(cur_labels)\n",
    "\n",
    "ax.set_xlabel('site type', fontsize=fontsize)\n",
    "ax.set_ylabel('Rh atoms per surface type [%]', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "draw_ind = 1\n",
    "offsets = np.array([-0.3, 0, 0.3])\n",
    "alphas = [0.2, 0.5, 1]\n",
    "width = 0.3\n",
    "fontsize = 17\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('mcmd')\n",
    "\n",
    "cur_labels = []\n",
    "for ii_label, label in enumerate(labels+['bulk', 'non-classifiable']):\n",
    "    if used_cats[draw_ind, ii_label]:\n",
    "        cur_labels.append(label)\n",
    "\n",
    "draw_percentages = measurement_count[draw_ind, :, :] / (n_ts[draw_ind, :, np.newaxis] * n_rhod)\n",
    "draw_percentages *= 100\n",
    "draw_percentages = measurement_count[draw_ind, :, :]\n",
    "n_cats = np.sum(np.asarray(used_cats[draw_ind, :], np.int8))\n",
    "cat_locs = np.arange(n_cats)\n",
    "\n",
    "for ii_bar in range(3):\n",
    "    ax.bar(cat_locs + offsets[ii_bar], draw_percentages[ii_bar, used_cats[draw_ind, :]], width=width, label=label_list[ii_bar])\n",
    "\n",
    "    for ll_ann, annotation in enumerate(draw_percentages[ii_bar, used_cats[draw_ind, :]]):\n",
    "        ax.annotate(\n",
    "            \"%.4f\"%annotation,\n",
    "            [cat_locs[ll_ann]+offsets[ii_bar], annotation*1.1], \n",
    "            ha='center', rotation=45, fontsize=fontsize-10\n",
    "        )\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks(cat_locs)\n",
    "ax.set_xticklabels(cur_labels)\n",
    "\n",
    "ax.set_xlabel('site type', fontsize=fontsize)\n",
    "ax.set_ylabel('Rh atoms per surface type [%]', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "89c38489e3a3631c28bb34ee29ee1d19eecb11ca19c23361330a3cc012ae8209"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
